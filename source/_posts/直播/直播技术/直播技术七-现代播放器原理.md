---
title: 直播技术七-现代播放器原理
date: 2019-08-05 13:42:14
categories:
  - 直播
tags:
  - 直播
---

# 播放器构成

通常来说，一个典型的播放器可以分解成三部分：UI、 多媒体引擎和解码器，如图所示：

{% asset_img 播放器构成.png %}

甚至为了在浏览器和原生播放器之间统一用户体验，可以考虑使用 React Native 来进行 UI 或者皮肤的开发，使用 Haxe 来进行业务逻辑的开发，这些优秀的库都可以在多种不同类型的设备之间共用同一套代码库。

# 用户界面（UI）

通过三部分不同的功能特性定义了终端用户的观看体验：皮肤（播放器的外观设计）、UI逻辑（所有可自定义的特性如播放列表和社交分享等）以及业务逻辑部分（特定的业务逻辑特性如广告、设备兼容性逻辑以及认证管理等）。

## 皮肤

进度控制条、按钮和动画图标等等

## UI 逻辑

播放过程中和用户交互方面所有可见的交互：播放列表、缩略图、播放频道的选择以及社交媒体分享等

UI 逻辑部分，最好的实现方式是让各种特性都以插件/模块的形式添加到 UI 核心模块中。

## 业务逻辑

虽然终端用户没法直接和这部分功能进行交互，这部分构成了你业务的独特性：认证和支付、频道和播放列表的获取，以及广告等。这里也包含一些技术相关的东西，比如用于 A/B 测试模块，以及和设备相关的配置，这些配置用于在多种不同类型的设备之间选择多个不同的媒体引擎。

### 设备检测与配置逻辑

这是最重要的特性之一，因为它将**播放和渲染剥离**开来了。

例如，基于你浏览器的不同版本，播放器可能会自动为你选择一个基于 HTML5 MSE 的多媒体引擎 hls.js，或者为你选择一个基于 flash 的播放引擎 FlasHls 来播放 HLS 视频流。这部分的最大特点在于，无论你使用什么样的底层引擎，在上层都可以使用相同的 JavaScript 或者 CSS 来定制你的 UI 或者业务逻辑。

能够检测用户设备的能力允许你按需配置终端用户的体验：如果是在移动设备而非 4K 屏幕设备上播放，你可能需要从一个较低的码率开始。

### A/B 测试逻辑

A/B 测试是为了能够在生产环节中灰度部分用户。

例如，你可能会给部分 Chrome 用户提供一个新的按钮或者新的多媒体引擎，并且还能保证它所有的工作都正常如期进行。

### 广告（可选）

在客户端处理广告是最复杂的业务逻辑之一。

它们能够帮你从广告服务器中拉取视频广告，放在视频的前期、中期和后期进行播放，且不可跳过。

# 多媒体引擎

随着主播控制和定制播放器需求的递增，一些新的播放器中慢慢也开放了一些更为底层的 API（如 Web 上的 Media Source Extensons，Flash 上的 Netstream 以及 Android 平台的 Media Codec），并迅速吸引来了很多基于这些底层 API 的强大而健壮的多媒体引擎。

## 1. 声明文件解释和解析器

在基于 HTTP 的视频流中，一切都是以一个描述文件开始。该声明文件包含了媒体服务器所需理解的元信息：有多少种不同类型的视频质量、语言以及字母等，它们分别是什么。解析器从 XML 文件（对于 HLS 来说则是一种特殊的 m3u8 文件）中取得描述信息，然后从这些信息中取得正确的视频信息。当然，媒体服务器的类型很多，并不是所有都正确的实现了规范，因此解析器可能需要处理一些额外的实现错误。

一旦提取了视频信息，解析器则会从中解析出数据，用于构建流式的视觉图像，同时知道如何获取不同的视频片段。在某些多媒体引擎中，这些视觉图像先以一副抽象多媒体图的形式出现，然后在屏幕上绘制出不同 HTTP 视频流格式的差异特征。

在直播流场景中，解析器也必须周期性的重新获取声明文件，以便获得最新的视频片段信息。

## 2. 下载器（下载声明文件、多媒体片段以及密钥）

下载器是一个包装了处理 HTTP 请求原生 API 的模块。它不仅用于下载多媒体文件，在必要的时候也可以用于下载声明文件和 DRM 密钥。下载器在处理网络错误和重试方面扮演着非常重要的角色，同时能够收集当前可用带宽的数据。

注意：下载多媒体文件可能使用 HTTP 协议，也可能使用别的协议，如点对点实时通信场景中的 WebRTC 协议。

## 3. 流播放引擎

流播放引擎是和解码器 API 交互的中央模块，它将不同的多媒体片段导入编码器，同时处理多码率切换和播放时的差异性（如声明文件和视频切片的差异，以及卡顿时的自动跳帧）。

## 4. 资源质量参数预估器（带宽、CPU 和帧率等）

预估器从各种不同的维度获取数据（块大小，每片段下载时间，以及跳帧数），并将其汇聚起来用于估算用户可用的带宽和 CPU 计算能力。这些输出用于 **ABR** （Adaptive Bitrate, 自适应码率）切换控制器做判断。

## 5. ABR 切换控制器

ABR 切换器可能是多媒体引擎中最为关键的部分——通常也是大家最为忽视的部分。该控制器读取预估器输出的数据（带宽和跳帧数），使用自定义算法根据这些数据做出判断，告诉流播放引擎是否需要切换视频或者音频质量。

该领域有很多研究性的工作，其中最大的难点在于在再缓冲风险和切换频率（太频繁的切换可能导致糟糕的用户体验）之间找到平衡。

## 6. DRM 管理器（可选组件）

Digital Rights Management, 数字版权管理

今天所有的付费视频服务都基于 DRM 管理，而 DRM 则很大程度上依赖于平台或者设备，我们将在后续讲解播放器的时候看到。

多媒体引擎中的 DRM 管理器是更底层**解码器中内容解密 API 的包装**。

只要有可能，它会尽量通过抽象的方式来屏蔽浏览器或者操作系统实现细节的差异性。该组件通常和流处理引擎紧密连接在一起，因为它经常和解码器层交互。

## 7. 格式转换复用器（可选组件）

后文中我们将看到，每个平台在封包和编码方面都有它的局限性（Flash 读的是 FLV 容器封装的 H.264/AAC 文件，MSE 读的是 ISOBMFF 容器封装的 H.264/AAC 文件）。这就导致了有些视频片段在解码之前需要进行格式转换。例如，有了 MPEG2-TS 到 ISOBMFF 的格式转换复用器之后，hls.js 就能使用 MSE 格式的内容来播放 HLS 视频流。多媒体引擎层面的格式转换复用器曾经遭受质疑；然而，随着现代 JavaScript 或者 Flash 解释权性能的提升，它带来的性能损耗几乎可以忽略不计，对用户体验也不会造成多大的影响。

# 解码器和 DRM 管理器

出于解码性能（解码器）和安全考虑（DRM），解码器和 DRM 管理器与操作**系统**平台密切绑定。 

{% asset_img 解码器、渲染器和 DRM 工作流程图.png %}

## 解码器

解码器处理最底层播放相关的逻辑。它将不同封装格式的视频进行**解包**，并将其内容**解码**，然后将解码后的视频帧交给操作系统进行渲染，最终让终端用户看到。

由于视频压缩算法变得越来越复杂，解码过程是一个需要密集计算的过程，并且为了保证解码性能和流畅的播放体验，解码过程需要强依赖于操作系统和硬件。现在的大部分解码都依赖于 **GPU** 加速解码的帮助（这也是为什么免费而更强大的 VP9 解码器没有赢得 H.264 市场地位的原因之一）。如果没有 GPU 的加速，解码一个 1080P 的视频就会占去 70% 左右的 CPU 计算量，并且丢帧率还可能很严重。

在解码和渲染视频帧的基础之上，管理器也提供了一个原生的** buffer**，多媒体引擎可以直接与该 buffer 进行交互，实时了解它的大小并在必要的时候刷新它。

##  DRM 管理器

# 总结

在 Web 平台，得益于多媒体引擎如 dash.js、Shaka Player 和 hls.js 这些趋于成熟库的帮助， MSE 和 EME 正在成为播放的新标准，同时也越来越多有影响力的厂家使用这些播放引擎。近年来，注意力也开始伸向机顶盒和互联网电视，我们也看到越来越多这样的新设备使用 MSE 来作为其底层多媒体处理引擎。

# 参考&扩展

- [《视频直播技术详解》系列之七：现代播放器原理](https://blog.qiniu.com/archives/7040)
<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="随心而动，随刃而行">
<meta property="og:type" content="website">
<meta property="og:title" content="风">
<meta property="og:url" content="http://yoursite.com/page/11/index.html">
<meta property="og:site_name" content="风">
<meta property="og:description" content="随心而动，随刃而行">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="风">
<meta name="twitter:description" content="随心而动，随刃而行">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/11/"/>





  <title>风</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">风</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">技术博客</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/05/直播/ijkplayer/ijkplayer系列一-开篇/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="风">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="风">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/05/直播/ijkplayer/ijkplayer系列一-开篇/" itemprop="url">ijkplayer系列一-开篇</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-05T15:22:14+08:00">
                2019-08-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/直播/" itemprop="url" rel="index">
                    <span itemprop="name">直播</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>ijkplayer 是一款比较出众的开源 Android/IOS 跨平台播放器，基于 ffplay，API 易于集成，可定制编译控制体积。</p>
<p>本系列基于 <strong>0.8.8</strong> 版本(目前<strong>最新</strong>版本)的 ijkplayer ，对其源码进行剖析，涉及到不同平台下的封装接口或处理方式时，均以 <strong>Android</strong> 为例。</p>
<p>ijkplayer android 集成了三种播放器实现：</p>
<ul>
<li><strong>AndroidMediaPlayer</strong>：即安卓系统自带的播放器 <strong>MediaPlayer</strong>，基于 MediaCodec、AudioTrack 等安卓系统 API.</li>
<li><strong>IjkExoMediaPlayer</strong>：即谷歌新推出的 <strong>ExoPlayer</strong>，同样是基于 MediaCodec、AudioTrack 等安卓系统 API，但相比 MediaPlayer 具有支持 DASH、高级 HLS、自定义扩展等优点。</li>
<li><strong>IjkMediaPlayer</strong>：基于 FFmpeg 的 <strong>ffplay</strong>，集成了 MediaCodec 硬解码器、Opengl 渲染方式等。</li>
</ul>
<p>一般而言， ijkplayer 就是指 <strong>IjkMediaPlayer</strong>，本文分析的对象就是 IjkMediaPlayer.</p>
<h1 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ijkplayer（项目文件夹）</span><br><span class="line">	├──tools  - 初始化项目工程脚本</span><br><span class="line">	├──config - 编译ffmpeg使用的配置文件</span><br><span class="line">	├──extra - 存放编译ijkplayer所需的依赖源文件, 如ffmpeg、openssl等</span><br><span class="line">	├──ijkmedia - 核心代码</span><br><span class="line">		├──ijkplayer - 播放器数据下载及解码相关</span><br><span class="line">		├──ijksdl - 音视频数据渲染相关</span><br><span class="line">	├──android -  android平台上的上层接口封装以及平台相关方法</span><br><span class="line">	├──ios - iOS平台上的上层接口封装以及平台相关方法</span><br></pre></td></tr></table></figure>
<h1 id="功能实现的平台差异"><a href="#功能实现的平台差异" class="headerlink" title="功能实现的平台差异"></a>功能实现的平台差异</h1><p>iOS和Android平台的差异主要表现在</p>
<ul>
<li>视频硬件解码</li>
<li>音频渲染</li>
<li>视频渲染</li>
</ul>
<table>
<thead>
<tr>
<th>Platform</th>
<th>Hardware Codec</th>
<th>Video Render</th>
<th>Video Output</th>
<th>Audio Output</th>
</tr>
</thead>
<tbody>
<tr>
<td>Android</td>
<td>MediaCodec</td>
<td>OpenGL ES、MediaCodec</td>
<td>NativeWindow、OpenGL ES</td>
<td>OpenSL ES、AudioTrack</td>
</tr>
<tr>
<td>iOS</td>
<td>VideoToolBox</td>
<td>OpenGL ES</td>
<td></td>
<td>AudioQueue</td>
</tr>
</tbody>
</table>
<h1 id="参考-amp-扩展"><a href="#参考-amp-扩展" class="headerlink" title="参考&amp;扩展"></a>参考&amp;扩展</h1><ul>
<li><a href="https://github.com/bilibili/ijkplayer" target="_blank" rel="noopener">github</a></li>
<li><a href="https://www.jianshu.com/p/5345ab4cf979" target="_blank" rel="noopener">ijkplayer 源码分析（上）</a> 王英豪，基于k0.8.8版本</li>
<li><a href="https://cloud.tencent.com/developer/article/1032547" target="_blank" rel="noopener">ijkplayer框架深入剖析</a> 金山云团队，基于k0.7.6版本</li>
<li><a href="https://www.jianshu.com/p/7d9b86919682" target="_blank" rel="noopener">ijkplayer视频播放器源码分析(android)</a> 尸情化异，基于k0.5.1版本，系列专栏5篇：使用，初始化，数据读取，音频解码播放，视频解码播放</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/05/直播/直播技术/直播技术七-现代播放器原理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="风">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="风">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/05/直播/直播技术/直播技术七-现代播放器原理/" itemprop="url">直播技术七-现代播放器原理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-05T13:42:14+08:00">
                2019-08-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/直播/" itemprop="url" rel="index">
                    <span itemprop="name">直播</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="播放器构成"><a href="#播放器构成" class="headerlink" title="播放器构成"></a>播放器构成</h1><p>通常来说，一个典型的播放器可以分解成三部分：UI、 多媒体引擎和解码器，如图所示：</p>
<img src="/2019/08/05/直播/直播技术/直播技术七-现代播放器原理/播放器构成.png">
<p>甚至为了在浏览器和原生播放器之间统一用户体验，可以考虑使用 React Native 来进行 UI 或者皮肤的开发，使用 Haxe 来进行业务逻辑的开发，这些优秀的库都可以在多种不同类型的设备之间共用同一套代码库。</p>
<h1 id="用户界面（UI）"><a href="#用户界面（UI）" class="headerlink" title="用户界面（UI）"></a>用户界面（UI）</h1><p>通过三部分不同的功能特性定义了终端用户的观看体验：皮肤（播放器的外观设计）、UI逻辑（所有可自定义的特性如播放列表和社交分享等）以及业务逻辑部分（特定的业务逻辑特性如广告、设备兼容性逻辑以及认证管理等）。</p>
<h2 id="皮肤"><a href="#皮肤" class="headerlink" title="皮肤"></a>皮肤</h2><p>进度控制条、按钮和动画图标等等</p>
<h2 id="UI-逻辑"><a href="#UI-逻辑" class="headerlink" title="UI 逻辑"></a>UI 逻辑</h2><p>播放过程中和用户交互方面所有可见的交互：播放列表、缩略图、播放频道的选择以及社交媒体分享等</p>
<p>UI 逻辑部分，最好的实现方式是让各种特性都以插件/模块的形式添加到 UI 核心模块中。</p>
<h2 id="业务逻辑"><a href="#业务逻辑" class="headerlink" title="业务逻辑"></a>业务逻辑</h2><p>虽然终端用户没法直接和这部分功能进行交互，这部分构成了你业务的独特性：认证和支付、频道和播放列表的获取，以及广告等。这里也包含一些技术相关的东西，比如用于 A/B 测试模块，以及和设备相关的配置，这些配置用于在多种不同类型的设备之间选择多个不同的媒体引擎。</p>
<h3 id="设备检测与配置逻辑"><a href="#设备检测与配置逻辑" class="headerlink" title="设备检测与配置逻辑"></a>设备检测与配置逻辑</h3><p>这是最重要的特性之一，因为它将<strong>播放和渲染剥离</strong>开来了。</p>
<p>例如，基于你浏览器的不同版本，播放器可能会自动为你选择一个基于 HTML5 MSE 的多媒体引擎 hls.js，或者为你选择一个基于 flash 的播放引擎 FlasHls 来播放 HLS 视频流。这部分的最大特点在于，无论你使用什么样的底层引擎，在上层都可以使用相同的 JavaScript 或者 CSS 来定制你的 UI 或者业务逻辑。</p>
<p>能够检测用户设备的能力允许你按需配置终端用户的体验：如果是在移动设备而非 4K 屏幕设备上播放，你可能需要从一个较低的码率开始。</p>
<h3 id="A-B-测试逻辑"><a href="#A-B-测试逻辑" class="headerlink" title="A/B 测试逻辑"></a>A/B 测试逻辑</h3><p>A/B 测试是为了能够在生产环节中灰度部分用户。</p>
<p>例如，你可能会给部分 Chrome 用户提供一个新的按钮或者新的多媒体引擎，并且还能保证它所有的工作都正常如期进行。</p>
<h3 id="广告（可选）"><a href="#广告（可选）" class="headerlink" title="广告（可选）"></a>广告（可选）</h3><p>在客户端处理广告是最复杂的业务逻辑之一。</p>
<p>它们能够帮你从广告服务器中拉取视频广告，放在视频的前期、中期和后期进行播放，且不可跳过。</p>
<h1 id="多媒体引擎"><a href="#多媒体引擎" class="headerlink" title="多媒体引擎"></a>多媒体引擎</h1><p>随着主播控制和定制播放器需求的递增，一些新的播放器中慢慢也开放了一些更为底层的 API（如 Web 上的 Media Source Extensons，Flash 上的 Netstream 以及 Android 平台的 Media Codec），并迅速吸引来了很多基于这些底层 API 的强大而健壮的多媒体引擎。</p>
<h2 id="1-声明文件解释和解析器"><a href="#1-声明文件解释和解析器" class="headerlink" title="1. 声明文件解释和解析器"></a>1. 声明文件解释和解析器</h2><p>在基于 HTTP 的视频流中，一切都是以一个描述文件开始。该声明文件包含了媒体服务器所需理解的元信息：有多少种不同类型的视频质量、语言以及字母等，它们分别是什么。解析器从 XML 文件（对于 HLS 来说则是一种特殊的 m3u8 文件）中取得描述信息，然后从这些信息中取得正确的视频信息。当然，媒体服务器的类型很多，并不是所有都正确的实现了规范，因此解析器可能需要处理一些额外的实现错误。</p>
<p>一旦提取了视频信息，解析器则会从中解析出数据，用于构建流式的视觉图像，同时知道如何获取不同的视频片段。在某些多媒体引擎中，这些视觉图像先以一副抽象多媒体图的形式出现，然后在屏幕上绘制出不同 HTTP 视频流格式的差异特征。</p>
<p>在直播流场景中，解析器也必须周期性的重新获取声明文件，以便获得最新的视频片段信息。</p>
<h2 id="2-下载器（下载声明文件、多媒体片段以及密钥）"><a href="#2-下载器（下载声明文件、多媒体片段以及密钥）" class="headerlink" title="2. 下载器（下载声明文件、多媒体片段以及密钥）"></a>2. 下载器（下载声明文件、多媒体片段以及密钥）</h2><p>下载器是一个包装了处理 HTTP 请求原生 API 的模块。它不仅用于下载多媒体文件，在必要的时候也可以用于下载声明文件和 DRM 密钥。下载器在处理网络错误和重试方面扮演着非常重要的角色，同时能够收集当前可用带宽的数据。</p>
<p>注意：下载多媒体文件可能使用 HTTP 协议，也可能使用别的协议，如点对点实时通信场景中的 WebRTC 协议。</p>
<h2 id="3-流播放引擎"><a href="#3-流播放引擎" class="headerlink" title="3. 流播放引擎"></a>3. 流播放引擎</h2><p>流播放引擎是和解码器 API 交互的中央模块，它将不同的多媒体片段导入编码器，同时处理多码率切换和播放时的差异性（如声明文件和视频切片的差异，以及卡顿时的自动跳帧）。</p>
<h2 id="4-资源质量参数预估器（带宽、CPU-和帧率等）"><a href="#4-资源质量参数预估器（带宽、CPU-和帧率等）" class="headerlink" title="4. 资源质量参数预估器（带宽、CPU 和帧率等）"></a>4. 资源质量参数预估器（带宽、CPU 和帧率等）</h2><p>预估器从各种不同的维度获取数据（块大小，每片段下载时间，以及跳帧数），并将其汇聚起来用于估算用户可用的带宽和 CPU 计算能力。这些输出用于 <strong>ABR</strong> （Adaptive Bitrate, 自适应码率）切换控制器做判断。</p>
<h2 id="5-ABR-切换控制器"><a href="#5-ABR-切换控制器" class="headerlink" title="5. ABR 切换控制器"></a>5. ABR 切换控制器</h2><p>ABR 切换器可能是多媒体引擎中最为关键的部分——通常也是大家最为忽视的部分。该控制器读取预估器输出的数据（带宽和跳帧数），使用自定义算法根据这些数据做出判断，告诉流播放引擎是否需要切换视频或者音频质量。</p>
<p>该领域有很多研究性的工作，其中最大的难点在于在再缓冲风险和切换频率（太频繁的切换可能导致糟糕的用户体验）之间找到平衡。</p>
<h2 id="6-DRM-管理器（可选组件）"><a href="#6-DRM-管理器（可选组件）" class="headerlink" title="6. DRM 管理器（可选组件）"></a>6. DRM 管理器（可选组件）</h2><p>Digital Rights Management, 数字版权管理</p>
<p>今天所有的付费视频服务都基于 DRM 管理，而 DRM 则很大程度上依赖于平台或者设备，我们将在后续讲解播放器的时候看到。</p>
<p>多媒体引擎中的 DRM 管理器是更底层<strong>解码器中内容解密 API 的包装</strong>。</p>
<p>只要有可能，它会尽量通过抽象的方式来屏蔽浏览器或者操作系统实现细节的差异性。该组件通常和流处理引擎紧密连接在一起，因为它经常和解码器层交互。</p>
<h2 id="7-格式转换复用器（可选组件）"><a href="#7-格式转换复用器（可选组件）" class="headerlink" title="7. 格式转换复用器（可选组件）"></a>7. 格式转换复用器（可选组件）</h2><p>后文中我们将看到，每个平台在封包和编码方面都有它的局限性（Flash 读的是 FLV 容器封装的 H.264/AAC 文件，MSE 读的是 ISOBMFF 容器封装的 H.264/AAC 文件）。这就导致了有些视频片段在解码之前需要进行格式转换。例如，有了 MPEG2-TS 到 ISOBMFF 的格式转换复用器之后，hls.js 就能使用 MSE 格式的内容来播放 HLS 视频流。多媒体引擎层面的格式转换复用器曾经遭受质疑；然而，随着现代 JavaScript 或者 Flash 解释权性能的提升，它带来的性能损耗几乎可以忽略不计，对用户体验也不会造成多大的影响。</p>
<h1 id="解码器和-DRM-管理器"><a href="#解码器和-DRM-管理器" class="headerlink" title="解码器和 DRM 管理器"></a>解码器和 DRM 管理器</h1><p>出于解码性能（解码器）和安全考虑（DRM），解码器和 DRM 管理器与操作<strong>系统</strong>平台密切绑定。 </p>

<h2 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h2><p>解码器处理最底层播放相关的逻辑。它将不同封装格式的视频进行<strong>解包</strong>，并将其内容<strong>解码</strong>，然后将解码后的视频帧交给操作系统进行渲染，最终让终端用户看到。</p>
<p>由于视频压缩算法变得越来越复杂，解码过程是一个需要密集计算的过程，并且为了保证解码性能和流畅的播放体验，解码过程需要强依赖于操作系统和硬件。现在的大部分解码都依赖于 <strong>GPU</strong> 加速解码的帮助（这也是为什么免费而更强大的 VP9 解码器没有赢得 H.264 市场地位的原因之一）。如果没有 GPU 的加速，解码一个 1080P 的视频就会占去 70% 左右的 CPU 计算量，并且丢帧率还可能很严重。</p>
<p>在解码和渲染视频帧的基础之上，管理器也提供了一个原生的<strong> buffer</strong>，多媒体引擎可以直接与该 buffer 进行交互，实时了解它的大小并在必要的时候刷新它。</p>
<h2 id="DRM-管理器"><a href="#DRM-管理器" class="headerlink" title="DRM 管理器"></a>DRM 管理器</h2><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>在 Web 平台，得益于多媒体引擎如 dash.js、Shaka Player 和 hls.js 这些趋于成熟库的帮助， MSE 和 EME 正在成为播放的新标准，同时也越来越多有影响力的厂家使用这些播放引擎。近年来，注意力也开始伸向机顶盒和互联网电视，我们也看到越来越多这样的新设备使用 MSE 来作为其底层多媒体处理引擎。</p>
<h1 id="参考-amp-扩展"><a href="#参考-amp-扩展" class="headerlink" title="参考&amp;扩展"></a>参考&amp;扩展</h1><ul>
<li><a href="https://blog.qiniu.com/archives/7040" target="_blank" rel="noopener">《视频直播技术详解》系列之七：现代播放器原理</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/03/直播/直播技术/直播技术六-延迟优化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="风">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="风">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/03/直播/直播技术/直播技术六-延迟优化/" itemprop="url">直播技术六-延迟优化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-03T15:42:14+08:00">
                2019-08-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/直播/" itemprop="url" rel="index">
                    <span itemprop="name">直播</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>直播系统是一个复杂的工程系统，要做到非常低延迟的直播，需要复杂的系统工程优化和对各组件非常熟悉的掌握</p>
<p>优化低延迟的时候并不是只关注「低延迟」，而是在保证其它条件不影响用户体验的情况下尽量做到低延迟</p>
<h1 id="编码优化"><a href="#编码优化" class="headerlink" title="编码优化"></a>编码优化</h1><ol>
<li>确保 Codec 开启了最低延迟的设置。Codec 一般都会有低延迟优化的开关，对于 H.264 来说其效果尤其明显。很多人可能不知道 H.264 的解码器正常情况下会在显示之前缓存一定的视频帧，对于 QCIF 分辨率大小的视频（176 × 144）一般会缓存 16 帧，对于 720P 的视频则缓存 5 帧。对于第一帧的读取来说，这是一个很大的延迟。如果你的视频不是使用 H.264 来编码压缩的，确保没有使用到 B 帧，它对延迟也会有较大的影响，因为视频中 B 帧的解码依赖于前后的视频帧，会增加延迟。</li>
</ol>
<ol start="2">
<li>编码器一般都会有码控造成的延迟，一般也叫做初始化延迟或者视频缓存检验器 VBV 的缓存大小，把它当成编码器和解码器比特流之间的缓存，在不影响视频质量的情况下可以将其设置得尽可能小也可以降低延迟。</li>
</ol>
<ol start="3">
<li>如果是仅仅优化首开延迟，可以在视频帧间插入较多的关键帧，这样客户端收到视频流之后可以尽快解码。但如果需要优化传输过程中的累计延迟，尽可能少使用关键帧也就是 I 帧（GOP 变大），在保证同等视频质量的情况下，I 帧越多，码率越大，传输所需的网络带宽越多，也就意味着累计延迟可能越大。这个优化效果可能在秒级延迟的系统中不是很明显，但是在 100 ms 甚至更低延迟的系统中就会非常明显。同时，尽量使用 ACC-LC Codec 来编码音频，HE-ACC 或者 HE-ACC 2 虽然编码效率高，但是编码所需时间更长，而产生更大体积的音频造成的传输延迟对于视频流的传输来说影响更小。</li>
</ol>
<ol start="4">
<li>不要使用视频 MJPEG 的视频压缩格式，至少使用不带 B 帧的 MPEG4 视频压缩格式（Simple profile），甚至最好使用 H.264 baseline profile（X264 还有一个「-tune zerolatency」的优化开关）。这样一个简单的优化可以降低延迟，因为它能够以更低的码率编码全帧率视频。</li>
</ol>
<ol start="5">
<li>如果使用了 FFmpeg，降低「-probesize 」和「 -analyze duration」参数的值，这两个值用于视频帧信息监测和用于监测的时长，这两个值越大对编码延迟的影响越大，在直播场景下对于视频流来说 analyzeduration 参数甚至没有必要设定。</li>
</ol>
<ol start="6">
<li>固定码率编码 CBR 可以一定程度上消除网络抖动影响，如果能够使用可变码率编码 VBR 可以节省一些不必要的网络带宽，降低一定的延迟。因此建议尽量使用 VBR 进行编码。</li>
</ol>
<h1 id="传输协议优化"><a href="#传输协议优化" class="headerlink" title="传输协议优化"></a>传输协议优化</h1><ol>
<li>在服务端节点和节点之间尽量使用 RTMP 而非基于 HTTP 的 HLS 协议进行传输，这样可以降低整体的传输延迟。这个主要针对终端用户使用 HLS 进行播放的情况。</li>
</ol>
<ol start="2">
<li>如果终端用户使用 RTMP 来播放，尽量在靠近推流端的收流节点进行转码，这样传输的视频流比原始视频流更小。</li>
</ol>
<ol start="3">
<li>如果有必要，可以使用定制的 UDP 协议来替换 TCP 协议，省去弱网环节下的丢包重传可以降低延迟。它的主要缺点在于，基于 UDP 协议进行定制的协议的视频流的传输和分发不够通用，CDN 厂商支持的是标准的传输协议。另一个缺点在于可能出现丢包导致的花屏或者模糊（缺少关键帧的解码参考），这就要求协议定制方在 UDP 基础之上做好丢包控制。</li>
</ol>
<h1 id="传输网络优化"><a href="#传输网络优化" class="headerlink" title="传输网络优化"></a>传输网络优化</h1><ol>
<li>我们曾经介绍过实时流传输网络，它是一种新型的节点自组织的网状传输网络，既适合国内多运营商网络条件下的传输优化，也适合众多海外直播的需求。</li>
</ol>
<ol start="2">
<li>在服务端节点中缓存当前 GOP，配合播放器端优化视频首开时间。</li>
</ol>
<ol start="3">
<li>服务端实时记录每个视频流流向每个环节时的秒级帧率和码率，实时监控码率和帧率的波动。</li>
</ol>
<ol start="4">
<li>客户端（推流和播放）通过查询服务端准实时获取当前最优节点（5 秒一次），准实时下线当前故障节点和线路。</li>
</ol>
<h1 id="推流、播放优化"><a href="#推流、播放优化" class="headerlink" title="推流、播放优化"></a>推流、播放优化</h1><ol>
<li>考察发送端系统自带的网络 buffer 大小，系统可能在发送数据之前缓存数据，这个参数的调优也需要找到一个平衡点。</li>
</ol>
<ol start="2">
<li>播放端缓存控制对于视频的首开延迟也有较大影响，如果仅优化首开延迟，可以在 0 缓存情况下在数据到达的时候立即解码。但如果在弱网环境下为了消除网络抖动造成的影响，设置一定的缓存也有必要，因此需要在直播的稳定性和首开延迟优化上找到平衡，调整优化缓冲区大小这个值。</li>
</ol>
<ol start="3">
<li>播放端动态 buffer 策略，这是上面播放端缓存控制的改进版本。如果只是做 0 缓存和固定大小的缓存之间进行选择找到平衡，最终还是会选择一个固定大小的缓存，这对亿级的移动互联网终端用户来说并不公平，他们不同的网络状况决定了这个固定大小的缓存并不完全合适。因此，我们可以考虑一种「动态 buffer 策略」，在播放器开启的时候采用非常小甚至 0 缓存的策略，通过对下载首片视频的耗时来决定下一个时间片的缓存大小，同时在播放过程中实时监测当前网络，实时调整播放过程中缓存的大小。这样即可做到极低的首开时间，又可能够尽量消除网络抖动造成的影响。</li>
</ol>
<ol start="4">
<li>动态码率播放策略。除了动态调整 buffer 大小的策略之外，也可以利用实时监测的网络信息来动态调整播放过程中的码率，在网络带宽不足的情况下降低码率进行播放，减少延迟。</li>
</ol>
<h1 id="参考-amp-扩展"><a href="#参考-amp-扩展" class="headerlink" title="参考&amp;扩展"></a>参考&amp;扩展</h1><ul>
<li><a href="https://blog.qiniu.com/archives/6996" target="_blank" rel="noopener">《视频直播技术详解》系列之六：延迟优化</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/03/直播/直播技术/直播技术五-推流和传输/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="风">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="风">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/03/直播/直播技术/直播技术五-推流和传输/" itemprop="url">直播技术五-推流和传输</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-03T15:02:14+08:00">
                2019-08-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/直播/" itemprop="url" rel="index">
                    <span itemprop="name">直播</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>推流是直播的第一公里，直播的推流对整个直播链路影响非常大，如果推流的网络不稳定，无论我们如何做优化，观众的体验都会很糟糕。所以也是我们<strong>排查问题的第一步</strong>，如何系统地解决这类问题需要我们对相关理论有基础的认识。</p>
<h1 id="推送协议"><a href="#推送协议" class="headerlink" title="推送协议"></a>推送协议</h1><table>
<thead>
<tr>
<th>协议</th>
<th>传输协议</th>
<th>视频封装格式</th>
<th>延时</th>
<th>数据分段</th>
<th>HTML 5</th>
</tr>
</thead>
<tbody>
<tr>
<td>RTMP</td>
<td>TCP</td>
<td>flv tag</td>
<td>1-3s</td>
<td>连续流</td>
<td>不支持</td>
</tr>
<tr>
<td>HTTP-FLV</td>
<td>HTTP-TCP</td>
<td>flv</td>
<td>1-3s</td>
<td>连续流</td>
<td>支持</td>
</tr>
<tr>
<td>HLS</td>
<td>HTTP-TCP</td>
<td>m3u8/ts</td>
<td>10s+</td>
<td>切片</td>
<td>支持</td>
</tr>
<tr>
<td>WebRTC</td>
<td>UDP</td>
<td></td>
<td></td>
<td></td>
<td>支持</td>
</tr>
<tr>
<td>基于 UDP 的私有协议</td>
<td>UDP</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>HLS慢</strong>的原因是<strong>等数据</strong>，缩短ts间隔与个数，HLS也能做到4秒+的延迟</p>
<table>
<thead>
<tr>
<th>协议</th>
<th>全称</th>
<th>说明</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td>RTMP</td>
<td>Real Time Messaging Protocol <br>实时消息传输协议</td>
<td>Adobe公司推出。<br>1. 用来进行实时数据通信的网络协议。<br>2. 目前主流的流媒体传输协议<br> 3. 广泛用于直播领域，绝大多数的直播产品都采用这个协议</td>
<td>1. CDN支持良好，主流的 CDN 厂商都支持。<br>2. 协议简单，在各平台上实现容易</td>
<td>1. 基于TCP，传输成本高，弱网环境丢包率高的情况下问题显著。<br>2. 非公共端口，可能会被防火墙阻拦。<br>3. 不支持浏览器推送。<br>4. Adobe 私有协议，Adobe 已经不再更新</td>
</tr>
<tr>
<td>HTTP-FLV</td>
<td></td>
<td>Adobe公司推出。将流媒体数据封装成 FLV 格式，通过 HTTP 协议传输给客户端</td>
<td>1. 依靠 MIME 的特性，根据协议中的 Content-Type 来选择相应的程序去处理。<br>2. 基于 HTTP/80 传输, 穿透防火墙。<br>3. 可以通过 HTTP 302 跳转灵活调度/负载均衡。<br>4.支持使用 HTTPS 加密传输</td>
<td>缓存流媒体资源在本地客户端，保密性不够好</td>
</tr>
<tr>
<td>HLS</td>
<td>HTTP Live Streaming</td>
<td>苹果推出的。<br>服务器端将流媒体数据切割成连续的时长较短的 ts 小文件，并通过 M3U8 索引文件按序访问 ts 文件</td>
<td>1. 在 HTML5 页面上实现播放非常简单。<br>2. 穿透防火墙。基于 HTTP/80 传输<br> 3. 性能高,自带多码率自适应</td>
<td>1. 实时性差，延迟高。慢的原因是等数据，缩短ts间隔与个数，HLS也能做到4秒+的延迟<br>2. 文件碎片。ts 切片较小，会造成海量小文件，对存储和缓存都有一定的挑战</td>
</tr>
<tr>
<td>WebRTC</td>
<td>Web Real-Time Communication <br>网页即时通信</td>
<td>1. 支持网页浏览器进行实时语音对话或视频对话的 API。<br>2. 主要应用于视频会议和连麦中</td>
<td>1. W3C 标准，主流浏览器支持程度高。<br>2. Google 在背后支撑，并在各平台有参考实现。<br>3.基于 SRTP 和 UDP，弱网情况优化空间大。<br>4.可以实现点对点通信，通信双方延时低</td>
<td>底层依赖ICE,STUN,TURN 传统 CDN 没有类似的服务提供</td>
</tr>
<tr>
<td>基于 UDP 的私有协议</td>
<td></td>
<td>有些直播应用会使用 UDP 做为底层协议开发自己的私有协议</td>
<td>基于UDP自研，弱网情况优化空间更大</td>
<td>1. 开发成本高。<br>2. 需要自建 CDN 或者和 CDN 达成协议。 <br>3. 独立作战，无法和社区一起演进</td>
</tr>
</tbody>
</table>
<h2 id="webrtc协议分层"><a href="#webrtc协议分层" class="headerlink" title="webrtc协议分层"></a>webrtc协议分层</h2><img src="/2019/08/03/直播/直播技术/直播技术五-推流和传输/webrtc协议分层.jpg">
<h1 id="传输网络"><a href="#传输网络" class="headerlink" title="传输网络"></a>传输网络</h1><p>推送出去的流媒体需要传输到观众，整个链路就是传输网络</p>
<p>这个成本巨高，直播服务提供商才自建传输网络。</p>
<h1 id="参考-amp-扩展"><a href="#参考-amp-扩展" class="headerlink" title="参考&amp;扩展"></a>参考&amp;扩展</h1><ul>
<li><a href="https://blog.qiniu.com/archives/6914" target="_blank" rel="noopener">《视频直播技术详解》系列之五：推流和传输</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/02/直播/直播技术/直播技术四-编码和封装/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="风">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="风">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/02/直播/直播技术/直播技术四-编码和封装/" itemprop="url">直播技术四-编码和封装</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-02T10:26:14+08:00">
                2019-08-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/直播/" itemprop="url" rel="index">
                    <span itemprop="name">直播</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>编码性能、编码速度和编码压缩比</strong>会直接影响整个流媒体传输的用户体验和传输成本。</p>
<p>编码完成后需要把内容按照一定标准封装到一个多媒体容器</p>
<h1 id="视频编码的意义"><a href="#视频编码的意义" class="headerlink" title="视频编码的意义"></a>视频编码的意义</h1><p>原始视频数据存储空间大，一个 1080P 50帧/秒 位宽(每个像素点位数)8bit 视频的码率为需要 937.5 Mbps，需要千兆上行宽带才能满足实时传输需求。而经过 H.264 编码压缩之后，视频码率只有 809 Kbps ,1 Mbps 的上行带宽就可以满足实时传输需求。所以从视频采集传感器采集来的原始视频势必要经过视频编码。</p>
<h1 id="视频编码原理"><a href="#视频编码原理" class="headerlink" title="视频编码原理"></a>视频编码原理</h1><h2 id="编码原理"><a href="#编码原理" class="headerlink" title="编码原理"></a>编码原理</h2><p>核心思想就是<strong>去除冗余信息</strong></p>
<p><strong>空间冗余</strong>：图像相邻像素之间有较强的相关性</p>
<p><strong>时间冗余</strong>：视频序列的相邻图像之间内容相似</p>
<p><strong>编码冗余</strong>：不同像素值出现的概率不同</p>
<p><strong>视觉冗余</strong>：人的视觉系统对某些细节不敏感</p>
<p><strong>知识冗余</strong>：规律性的结构可由先验知识和背景知识得到</p>
<h2 id="帧内编码"><a href="#帧内编码" class="headerlink" title="帧内编码"></a>帧内编码</h2><p><strong>帧内编码</strong>：对每一帧图片进行压缩编码</p>
<img src="/2019/08/02/直播/直播技术/直播技术四-编码和封装/帧内编码.png">
<p> <strong>MJPEG</strong> 编码就是这种编码方式，这种编码方式只有帧内编码，利用<strong>空间上的取样预测</strong>来编码。去除 <strong>空间冗余</strong></p>
<p>如图，绿色的部分就是当前待编码的区域，灰色就是尚未编码的区域，绿色区域可以根据已经编码的部分进行预测</p>
<h2 id="帧间编码"><a href="#帧间编码" class="headerlink" title="帧间编码"></a>帧间编码</h2><p><strong>帧间编码</strong>：帧和帧之间有时间的相关性，通过搜索算法选定了帧上的某些区域，然后通过计算当前帧和前后参考帧的向量差进行编码</p>
<img src="/2019/08/02/直播/直播技术/直播技术四-编码和封装/帧间编码.png">
<p>通过上面两个图 连续帧我们可以看到，滑雪的同学是向前位移的，但实际上是<strong>雪景在向后位移</strong>，P 帧通过参考帧（I 或其他 P 帧）就可以进行编码了，编码之后的大小非常小，压缩比非常高</p>
<p>上面两张图片的生成方式：</p>
<ul>
<li>生成带有移动矢量的视频</li>
<li>把每一帧都输出成图片</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg  -flags2 +export_mvs -i tutu.mp4 -vf codecview=mv=pf+bf+bb tutudebug2.mp4</span><br><span class="line"></span><br><span class="line">ffmpeg -i tutudebug2.mp4 &apos;tutunormal-%03d.bmp&apos;</span><br></pre></td></tr></table></figure>
<h2 id="编码流程"><a href="#编码流程" class="headerlink" title="编码流程"></a>编码流程</h2><img src="/2019/08/02/直播/直播技术/直播技术四-编码和封装/编码流程.png">
<p>编码流程是把帧内编码和帧间编码结合在一起</p>
<p>我们通常说的 I 帧和 P 帧就是分别采用了帧内编码和帧间编码</p>
<h1 id="编码器的选择"><a href="#编码器的选择" class="headerlink" title="编码器的选择"></a>编码器的选择</h1><h2 id="H-264-AVC"><a href="#H-264-AVC" class="headerlink" title="H.264/AVC"></a>H.264/AVC</h2><h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><p>AVC（Advanced Video Coding）高级视频编码</p>
<p>H.264/AVC <strong>低成本实现</strong>在<strong>更低带宽</strong>下提供优质视频（只有 MPEG-2，H.263 或 MPEG-4 第 2 部分的一半带宽或更少）</p>
<ul>
<li>不增加太多设计复杂度使得无法实现或实现成本过高</li>
<li>提供足够的灵活性，以在各种应用、网络及系统中使用</li>
</ul>
<p>这样的技术基础让 H.264 成为包括 YouTube 在内的在线视频公司采用它作为主要的编解码器。</p>
<h3 id="专利许可"><a href="#专利许可" class="headerlink" title="专利许可"></a>专利许可</h3><p>理论上讲使用 H.264 需要交纳不菲的专利费用。</p>
<h3 id="开源实现"><a href="#开源实现" class="headerlink" title="开源实现"></a>开源实现</h3><p>OpenH264、x264</p>
<h4 id="OpenH264"><a href="#OpenH264" class="headerlink" title="OpenH264"></a>OpenH264</h4><p>思科实现的开源 H.264 编码，思科把 OpenH264 实现的年度专利费交满后，OpenH264 事实上就可以免费自由的使用了。</p>
<h4 id="x264"><a href="#x264" class="headerlink" title="x264"></a>x264</h4><p>采用 GPL 授权的视频编码自由软件。x264 的主要功能在于进行 H.264/MPEG-4 AVC 的视频编码，而不是作为解码器（decoder）之用。</p>
<h4 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h4><p>OpenH264 CPU 的占用相对 x264低很多</p>
<p>OpenH264 只支持 baseline profile，x264 支持更多 profile</p>
<h2 id="HEVC-H-265"><a href="#HEVC-H-265" class="headerlink" title="HEVC/H.265"></a>HEVC/H.265</h2><h3 id="特性-1"><a href="#特性-1" class="headerlink" title="特性"></a>特性</h3><p>高效率视频编码（High Efficiency Video Coding，简称 HEVC）是 ITU-T H.264/MPEG-4 AVC 标准的<strong>继任者</strong>。</p>
<ul>
<li>提升视频质量</li>
<li>同时能达到 H.264/MPEG-4 AVC <strong>两倍压缩率</strong>（等同于同样画面质量下比特率减少了 50%）</li>
<li>可支持 <strong>4K</strong> 分辨率，最高分辨率可达到 8192×4320（8K 分辨率）。</li>
</ul>
<h3 id="专利许可-1"><a href="#专利许可-1" class="headerlink" title="专利许可"></a>专利许可</h3><p>要求所有使用 H.265 技术的支付专利使用费。包括</p>
<ul>
<li>内容制造商。<ul>
<li>上缴内容收入的 0.5%作为技术使用费</li>
<li>包括苹果、YouTube、Netflix、Facebook、亚马逊等</li>
<li>整个流媒体市场每年达到约 1000 亿美元的规模，且不断增长中，</li>
</ul>
</li>
<li>设备制造商。<ul>
<li>按每台设备收费</li>
<li>电视厂商、移动设备厂商、蓝光设备播放器、游戏机、录像机</li>
<li>之前已经发售的产品依然要追缴费用</li>
</ul>
</li>
</ul>
<h3 id="开源实现-1"><a href="#开源实现-1" class="headerlink" title="开源实现"></a>开源实现</h3><p>libde265、x265</p>
<h4 id="libde265-HEVC"><a href="#libde265-HEVC" class="headerlink" title="libde265 HEVC"></a>libde265 HEVC</h4><p>struktur 公司以开源许可证 GNU LesserGeneral Public License (LGPL) 提供，观众可以较慢的网速下欣赏到最高品质的影像。可以减少 50%流媒体播放所需要的带宽。高清或者 4K/8K 超高清流媒体播放，低延迟/低带宽视频会议，以及完整的移动设备覆盖。具有「拥塞感知」视频编码的稳定性，十分适合应用在 3/4G 和 LTE 网络。</p>
<h4 id="x265"><a href="#x265" class="headerlink" title="x265"></a>x265</h4><p>MulticoreWare 开发，并开源。采用 GPL 协议，但是资助这个项目的几个公司组成了联盟可以在非 GPL 协议下使用这个软件。</p>
<h2 id="VP8"><a href="#VP8" class="headerlink" title="VP8"></a>VP8</h2><h3 id="特性-2"><a href="#特性-2" class="headerlink" title="特性"></a>特性</h3><p>VP8 是一个开放的视频压缩格式，最早由 On2 Technologies 开发，随后由 Google 发布。</p>
<p>目前支持 VP8 的网页浏览器有 Opera、Firefox 和 Chrome。</p>
<h3 id="专利许可-2"><a href="#专利许可-2" class="headerlink" title="专利许可"></a>专利许可</h3><p>Google 获取 VP8 以及其之前的 VPx 等编码所可能侵犯的专利授权，然后无偿再次授权相关专利给 VP8 的用户。</p>
<h3 id="开源实现-2"><a href="#开源实现-2" class="headerlink" title="开源实现"></a>开源实现</h3><h4 id="libvpx"><a href="#libvpx" class="headerlink" title="libvpx"></a>libvpx</h4><p>libvpx 是 VP8 的唯一开源实现，由 On2 Technologies 开发，Google 收购后将其开放源码，License 非常宽松可以自由使用。</p>
<h2 id="VP9"><a href="#VP9" class="headerlink" title="VP9"></a>VP9</h2><h3 id="特性-3"><a href="#特性-3" class="headerlink" title="特性"></a>特性</h3><p>同画质下，比 VP8 编码减少 50% 的文件大小，在编码效率上超越 HEVC 编码。</p>
<p>目前支持 VP8 的网页浏览器有 Chromium、Chrome、Firefox </p>
<h3 id="专利许可-3"><a href="#专利许可-3" class="headerlink" title="专利许可"></a>专利许可</h3><p>VP9 是一个开放格式、无权利金的视频编码格式。</p>
<h3 id="开源实现-3"><a href="#开源实现-3" class="headerlink" title="开源实现"></a>开源实现</h3><h4 id="libvpx-1"><a href="#libvpx-1" class="headerlink" title="libvpx"></a>libvpx</h4><p>libvpx是 VP9 的唯一开源实现，由 Google 开发维护，里面有部分代码是 VP8 和 VP9 公用的，其余分别是 VP8 和 VP9 的编解码实现。</p>
<h1 id="FFmpeg"><a href="#FFmpeg" class="headerlink" title="FFmpeg"></a>FFmpeg</h1><p><a href="https://ffmpeg.org/download.html" target="_blank" rel="noopener">FFmpeg</a> 是一个自由软件，可以运行音频和视频多种格式的录影、转换、流功能.包含了 libavcodec -这是一个用于多个项目中音频和视频的解码器库，以及 libavformat -一个音频与视频格式转换库。</p>
<p>FF 指的是 Fast Forward</p>
<p>FFmpeg 是个优秀的工具，可以通过它完成很多日常的工作和实验，但是距离提供真正可用的流媒体服务、直播服务还有非常多的工作要做</p>
<h1 id="封装"><a href="#封装" class="headerlink" title="封装"></a>封装</h1><p>封装就是把<strong>编码内容</strong>（视频，音频，字幕，章节信息等）按照一定<strong>标准</strong>封装一个容器。</p>
<ul>
<li>播放简单</li>
<li>为媒体内容提供索引。可拖动</li>
</ul>
<h2 id="封装格式"><a href="#封装格式" class="headerlink" title="封装格式"></a>封装格式</h2><p>常见封装格式和音视频编码的组合方式</p>
<table>
<thead>
<tr>
<th>封装容器</th>
<th>视频流编码格式</th>
<th>音频流编码格式</th>
<th>说明</th>
<th>优点</th>
<th>缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td>AVI (.avi)</td>
<td>Xvid 或 Divx</td>
<td>MP3</td>
<td>Audio Video Interleaved 音频视频交错格式</td>
<td>图像质量好，可以保持alpha通道</td>
<td>体积过大，压缩标准不统一</td>
</tr>
<tr>
<td>DV-AVI (.avi)</td>
<td>Xvid 或 Divx</td>
<td>MP3</td>
<td>DV 是 Digital Video Format，数码摄像机使用这种格式</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Matroska (.mkv)</td>
<td>Xvid</td>
<td>MP3</td>
<td>可把多种不同编码的视频及 16 条或以上不同格式的音频和语言不同的字幕封装到一个 Matroska Media 档内</td>
<td>提供非常好的交互功能</td>
<td></td>
</tr>
<tr>
<td>Matroska (.mkv)</td>
<td>Xvid</td>
<td>AAC</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Matroska (.mkv)</td>
<td>H264</td>
<td>AAC</td>
<td>mkv最常用组合，体积最小，清晰度最高</td>
<td></td>
<td></td>
</tr>
<tr>
<td>MP4</td>
<td>Xvid</td>
<td>MP3</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>MP4</td>
<td>H.264</td>
<td>AAC</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>3GP</td>
<td>H.263</td>
<td>AAC</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>QuickTime File Format (.mov)</td>
<td></td>
<td></td>
<td>苹果开发，默认的播放器是苹果的 QuickTime</td>
<td>较高压缩比 较完美清晰度 可以保存 alpha 通道</td>
<td></td>
</tr>
<tr>
<td>MPEG (.mpg .mpeg .mpe .dat .vob .asf .3gp .mp4等)</td>
<td></td>
<td></td>
<td>Moving Picture Experts Group 运动图像专家组格式</td>
<td>MPEG－4 小体积 高质量</td>
<td></td>
</tr>
<tr>
<td>WMV 格式 (.wmv .asf)</td>
<td></td>
<td></td>
<td>Windows Media Video 微软推出</td>
<td>本地或网络播放,丰富的流间关系以及扩展性</td>
<td>网站播放需要安装 Windows Media Player</td>
</tr>
<tr>
<td>Real Video (.rm .rmvb)</td>
<td></td>
<td></td>
<td>用户可以使用 RealPlayer 根据不同的网络传输速率制定出不同的压缩比率。rmvb是升级版</td>
<td>低速网络实时播放</td>
<td></td>
</tr>
<tr>
<td>Flash Video (.flv)</td>
<td></td>
<td></td>
<td>Adobe Flash 延伸出来的的一种流行网络视频封装格式</td>
<td></td>
<td></td>
</tr>
<tr>
<td>MPEG2-TS (.ts)</td>
<td></td>
<td></td>
<td>Transport Stream「传输流」；又称 MTS、TS。用于数字电视广播系统</td>
<td>传输和存储包含音效、视频与通信协议各种数据。Media Player Classic、VLC 等软件可以直接播放</td>
<td></td>
</tr>
</tbody>
</table>
<p>目前，在流媒体传输，尤其是直播中主要采用的就是 FLV 和 MPEG2-TS 格式，分别用于 RTMP/HTTP-FLV 和 HLS 协议</p>
<h1 id="参考-amp-扩展"><a href="#参考-amp-扩展" class="headerlink" title="参考&amp;扩展"></a>参考&amp;扩展</h1><ul>
<li><a href="https://blog.qiniu.com/archives/6816" target="_blank" rel="noopener">《视频直播技术详解》之（四）：编码和封装</a></li>
<li><a href="https://blog.csdn.net/wishfly/article/details/50921712" target="_blank" rel="noopener">常见视频文件的编码方式和封装格式</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/01/直播/直播技术/直播技术三-处理/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="风">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="风">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/01/直播/直播技术/直播技术三-处理/" itemprop="url">直播技术三-处理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-01T18:02:14+08:00">
                2019-08-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/直播/" itemprop="url" rel="index">
                    <span itemprop="name">直播</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="开放式设计"><a href="#开放式设计" class="headerlink" title="开放式设计"></a>开放式设计</h1><img src="/2019/08/01/直播/直播技术/直播技术三-处理/处理.png">
<p>如上图所示，处理环节中分为<strong>音频和视频处理</strong></p>
<p>音频处理中具体包含混音(声音混淆)、降噪和声音特效等处理。在主播和观众<strong>连麦</strong>场景中，主播需要和某个或者多个观众进行对话，并将对话结果实时分享给其他所有观众，连麦的处理也有部分工作在推流端完成</p>
<p>视频处理中包含美颜、水印、以及各种自定义滤镜等处理。</p>
<p>除了要提供这些「标准」处理功能之外，我们还需要将该模块设计成可自由接入自定义处理功能的方式</p>
<h1 id="常见视频处理功能"><a href="#常见视频处理功能" class="headerlink" title="常见视频处理功能"></a>常见视频处理功能</h1><h2 id="美颜"><a href="#美颜" class="headerlink" title="美颜"></a>美颜</h2><p>美颜的主要原理是通过「磨皮+美白」来达到整体美颜的效果。</p>
<p>磨皮的技术术语是「去噪」，也即对图像中的噪点进行去除或者模糊化处理，常见的去噪算法有均值模糊、高斯模糊和中值滤波等。对整张图像进行「去噪」处理的时候不需要将眼睛也去掉，因此这个环节中也涉及到人脸和皮肤检测技术。</p>
<h2 id="视频水印"><a href="#视频水印" class="headerlink" title="视频水印"></a>视频水印</h2><p>用于简单是版权保护，或者进行广告设置。出于监管需求，相关部门也规定视频直播过程中必须打上水印，同时直播的视频必须录制存储下来保存一定的时间，并在录制的视频上打上水印。</p>
<p>视频水印包括<strong>播放器水印和视频内嵌水印</strong>两种方式可供选择。综合考虑云端录制对于水印的需求，一般会选择「视频内嵌水印」的方式打水印。</p>
<h2 id="滤镜"><a href="#滤镜" class="headerlink" title="滤镜"></a>滤镜</h2><p>iOS 端可以考虑使用 <a href="https://github.com/BradLarson/GPUImage" target="_blank" rel="noopener">GPUImage</a>，这是一个开源的基于GPU的图片或视频的处理框架，内置了多达120多种常见的滤镜效果。添加实时的滤镜只需要简单地添加几行代码，还可以基于这个库自己写算法实现更丰富端效果。</p>
<p>Android 有 GPUImage 这个库的<a href="https://github.com/CyberAgent/android-gpuimage" target="_blank" rel="noopener">移植</a>。Google 官方也开源了一个伟大的库 <a href="https://github.com/google/grafika" target="_blank" rel="noopener">grafika</a>，覆盖了 Android 上面很多多媒体和图形图像相关的处理</p>
<h2 id="连麦"><a href="#连麦" class="headerlink" title="连麦"></a>连麦</h2><img src="/2019/08/01/直播/直播技术/直播技术三-处理/连麦.png">
<p>连麦是互动直播中常见的需求，其流程如上图所示。主播和部分观众之间可以进行实时互动，然后将互动结果实时播放给其他观众观看。</p>
<p>基于以上业务需求，我们很容易想到基于单向直播原理，在主播端和连麦观众端进行<strong>双向推流和双向播流</strong>的方式互动，然后在<strong>服务端</strong>将两路推流<strong>合成</strong>一路推送给其他观众。但 RTMP 带来的延迟决定了这种方式无法做到用户可接受的互动直播。</p>
<h3 id="互动直播的主要技术难点"><a href="#互动直播的主要技术难点" class="headerlink" title="互动直播的主要技术难点"></a>互动直播的主要技术难点</h3><h4 id="低延迟互动"><a href="#低延迟互动" class="headerlink" title="低延迟互动"></a>低延迟互动</h4><p>保证主播和互动观众之间能够实时互动，两者之间就像电话沟通，因此必须保证两者能在<strong>秒级</strong>以内听到对方的声音，看到对方的视频；</p>
<h4 id="音画同步"><a href="#音画同步" class="headerlink" title="音画同步"></a>音画同步</h4><p>互动直播中对音画同步的需求比单向直播中更高，必须保证在音视频秒级传输情况下的<strong>秒级</strong>同步。</p>
<h4 id="音视频实时合成"><a href="#音视频实时合成" class="headerlink" title="音视频实时合成"></a>音视频实时合成</h4><p>其他观众需要实时观看到对话结果，因此需要在客户端或者服务端将画面和声音实时合成，然后以低成本高品质的方式传输观众端。</p>
<h3 id="互动直播的解决方案"><a href="#互动直播的解决方案" class="headerlink" title="互动直播的解决方案"></a>互动直播的解决方案</h3><h4 id="思科或者-WebEx"><a href="#思科或者-WebEx" class="headerlink" title="思科或者 WebEx"></a>思科或者 WebEx</h4><p>在视频和电话会议领域，目前比较成熟的方案是使用<strong>思科或者 WebEx</strong> 的方案，但这些商用的方案<strong>一不开源，二比较封闭，三成本比较高</strong>。</p>
<h4 id="WebRTC"><a href="#WebRTC" class="headerlink" title="WebRTC"></a>WebRTC</h4><p>对于互动人数比较少的互动直播，目前市场上比较成熟的方案是使用基于 <strong>WebRTC</strong> 的实时通讯方案。</p>
<p>基于该方案可以轻松实现多人（<strong>14 人以下</strong>）的多方实时通信</p>
<img src="/2019/08/01/直播/直播技术/直播技术三-处理/webrtc.png">
<p>上图是一个基于 WebRTC 协议实现多方实时通讯的示意图，本地用户（主播）和远程用户（连麦观众）之间的连接通过 RTCPeerConnection API 管理，这个 API 包装了底层流管理和信令控制相关的细节。</p>
<p>基于该方案的多方实时通信，如下图所示：</p>
<img src="/2019/08/01/直播/直播技术/直播技术三-处理/webrtc-network.png">
<p>在通信人数少的情况下，其复杂度相对简单。如 2 人情况下，直接连接。人数增多至 4 人之后，其可选的网络结构就增多了，如上图所示，可以每个点之间形成<strong>自组织网络</strong>的方式通信，也可以以 1 人为中心形成<strong>星型</strong>通信网络，还可以让大家都通过一个<strong>集中式的服务端</strong>进行通信。</p>
<p>为了提供 <strong>高性能、可伸缩</strong>的直播基础服务，七牛直播云经过评估选择了<strong>以主播为中心形成星形通信网络</strong>。同时，为了降低传输延迟，这里采用经过<strong>改造的 UDP 协议传输</strong>传输合成后的音视频实时传输到其他观众端</p>
<img src="/2019/08/01/直播/直播技术/直播技术三-处理/互动直播连麦.png">
<h1 id="参考-amp-扩展"><a href="#参考-amp-扩展" class="headerlink" title="参考&amp;扩展"></a>参考&amp;扩展</h1><ul>
<li><a href="https://blog.qiniu.com/archives/6795" target="_blank" rel="noopener">《视频直播技术详解》系列之三：处理</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/01/直播/直播技术/直播技术二-采集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="风">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="风">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/01/直播/直播技术/直播技术二-采集/" itemprop="url">直播技术二-采集</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-01T16:52:14+08:00">
                2019-08-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/直播/" itemprop="url" rel="index">
                    <span itemprop="name">直播</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="采集内容"><a href="#采集内容" class="headerlink" title="采集内容"></a>采集内容</h1><p>视频的采集涉及两方面数据的采集：<strong>音频采集和图像采集</strong>，它们分别对应两种完全不同的输入源和数据格式。</p>
<h2 id="音频采集"><a href="#音频采集" class="headerlink" title="音频采集"></a>音频采集</h2><p>音频数据既能与图像结合组合成视频数据，也能以纯音频的方式采集播放</p>
<p>音频的采集过程主要通过设备将环境中的模拟信号采集成 <strong>PCM</strong> (脉冲编码调制 - Pulse Code Modulation)编码的原始数据，然后编码压缩成 MP3 等格式的数据分发出去。</p>
<h3 id="常见的音频压缩格式"><a href="#常见的音频压缩格式" class="headerlink" title="常见的音频压缩格式"></a>常见的音频压缩格式</h3><p>有：MP3，AAC，HE-AAC，Opus，FLAC，Vorbis (Ogg)，Speex 和 AMR等。</p>
<h3 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h3><p>音频采集和编码主要面临的挑战在于：延时敏感、卡顿敏感、噪声消除（Denoise）、回声消除（AEC）、静音检测（VAD）和各种混音算法等。</p>
<h3 id="主要技术参数"><a href="#主要技术参数" class="headerlink" title="主要技术参数"></a>主要技术参数</h3><p>在音频采集阶段，参考的主要技术参数有 ：</p>
<h4 id="采样率-采样频率（samplerate）"><a href="#采样率-采样频率（samplerate）" class="headerlink" title="采样率/采样频率（samplerate）"></a>采样率/采样频率（samplerate）</h4><p>采样就是把模拟信号数字化的过程</p>
<p>采样频率越高，记录这一段音频信号所用的数据量就越大，同时音频质量也就越高。</p>
<ul>
<li>每秒的采样次数<ul>
<li>单位 Hz。Hz 是频率的单位。即每秒的周期次数(周期/秒)。电，磁，声波和机械振动周期循环时频率的单位。</li>
<li>声卡一般提供11.025kHz、22.05kHz和44.1kHz等不同的采样频率。</li>
</ul>
</li>
</ul>
<h4 id="位宽-采样位数"><a href="#位宽-采样位数" class="headerlink" title="位宽/采样位数"></a>位宽/采样位数</h4><ul>
<li>每次采样值数值大小的位数。<ul>
<li>单位 bit</li>
<li>常用的有8bits或16bits两种</li>
<li>采样位数越大，所能记录声音的变化度就越细腻，相应的数据量就越大。</li>
</ul>
</li>
</ul>
<h4 id="声道数（channels）"><a href="#声道数（channels）" class="headerlink" title="声道数（channels）"></a>声道数（channels）</h4><p>由于音频的采集和播放是可以叠加的，因此，可以同时从多个音频源采集声音，并分别输出到不同的扬声器，故声道数一般表示声音录制时的音源数量或回放时相应的扬声器数量。声道数为 1 和 2 分别称为单声道和双声道(立体声)，是比较常见的声道参数。</p>
<h4 id="音频帧（frame）"><a href="#音频帧（frame）" class="headerlink" title="音频帧（frame）"></a>音频帧（frame）</h4><p>音频跟视频很不一样，视频每一帧就是一张图像，而音频数据是流式的，本身没有明确的一帧帧的概念，在实际的应用中，为了音频算法处理/传输的方便，一般约定俗成取 2.5ms~60ms 为单位的数据量为一帧音频。这个时间被称之为“采样时间”，其长度没有特别的标准，它是根据编解码器和具体应用的需求来决定的。</p>
<h3 id="音频存储空间计算"><a href="#音频存储空间计算" class="headerlink" title="音频存储空间计算"></a>音频存储空间计算</h3><p><code>音频大小(bit/秒) = 采样频率(Hz,次数/秒) × 采样位数(bit) × 声道数</code></p>
<p><code>音频帧大小(bit) = 每秒音频大小(bit/秒) x 音频帧采样时长(秒)</code></p>
<p>假设某音频信号是采样率为 8kHz、双通道、位宽为 16bit，20ms 一帧</p>
<p>每秒音频size = 8000 x 2 x 16bit = 256000 bit = 32000 byte = 31.25 Kb</p>
<p>音频帧size = 32000 byte/s x 0.02s = 640 byte</p>
<h2 id="图像采集"><a href="#图像采集" class="headerlink" title="图像采集"></a>图像采集</h2><p>图像采集的图片组合成一组连续播放的动画，即构成视频中可肉眼观看的内容。</p>
<p>图像的采集过程主要由摄像头等设备拍摄成 <strong>YUV</strong> 编码的原始数据，然后经过编码压缩成 H.264 等格式的数据分发出去。</p>
<p>YUV是一种<strong>颜色编码</strong>方法。常用在<strong>图片或视频</strong>编码时</p>
<h3 id="常见的视频封装格式"><a href="#常见的视频封装格式" class="headerlink" title="常见的视频封装格式"></a>常见的视频封装格式</h3><p>有：MP4、3GP、AVI、MKV、WMV、MPG、VOB、FLV、SWF、MOV、RMVB 和 WebM 等。</p>
<h3 id="挑战-1"><a href="#挑战-1" class="headerlink" title="挑战"></a>挑战</h3><p>图像由于其直观感受最强并且体积也比较大，构成了一个视频内容的主要部分。图像采集和编码面临的主要挑战在于：设备兼容性差、延时敏感、卡顿敏感以及各种对图像的处理操作如美颜和水印等。</p>
<h3 id="主要技术参数-1"><a href="#主要技术参数-1" class="headerlink" title="主要技术参数"></a>主要技术参数</h3><p>在图像采集阶段，参考的主要技术参数有：</p>
<h4 id="图像传输格式"><a href="#图像传输格式" class="headerlink" title="图像传输格式"></a>图像传输格式</h4><p>通用影像传输格式（Common Intermediate Format）是视讯会议（video conference）中常使用的影像传输格式。</p>
<h4 id="图像格式"><a href="#图像格式" class="headerlink" title="图像格式"></a>图像格式</h4><p>通常采用 YUV 格式存储原始数据信息，其中包含用 8 位表示的黑白图像灰度值，以及可由 RGB 三种色彩组合成的彩色图像。</p>
<h4 id="传输通道"><a href="#传输通道" class="headerlink" title="传输通道"></a>传输通道</h4><p>正常情况下视频的拍摄只需 1 路通道，随着 VR 和 AR 技术的日渐成熟，为了拍摄一个完整的 360° 视频，可能需要通过不同角度拍摄，然后经过多通道传输后合成。</p>
<h4 id="分辨率"><a href="#分辨率" class="headerlink" title="分辨率"></a>分辨率</h4><p>随着设备屏幕尺寸的日益增多，视频采集过程中原始视频分辨率起着越来越重要的作用，后续处理环节中使用的所有视频分辨率的定义都以原始视频分辨率为基础。视频采集卡能支持的最大点阵反映了其分辨率的性能。</p>
<h4 id="采样频率"><a href="#采样频率" class="headerlink" title="采样频率"></a>采样频率</h4><p>采样频率反映了采集卡处理图像的速度和能力。在进行高度图像采集时，需要注意采集卡的采样频率是否满足要求。采样率越高，图像质量越高，同时保存这些图像信息的数据量也越大。</p>
<h3 id="视频存储空间计算"><a href="#视频存储空间计算" class="headerlink" title="视频存储空间计算"></a>视频存储空间计算</h3><h4 id="1080P、720P-像素"><a href="#1080P、720P-像素" class="headerlink" title="1080P、720P 像素"></a>1080P、720P 像素</h4><p>1080P的实际像素是 1920*1280, 相乘结果是 2073600，即有2073600个像素点， 也就是常说的 <strong>1080P为200万像素</strong></p>
<p>720P实际像素是1280×720， 相乘结果921600，即有921600个像素点，也就是常说的 <strong>720P为100万像素</strong></p>
<h4 id="视频存储空间"><a href="#视频存储空间" class="headerlink" title="视频存储空间"></a>视频存储空间</h4><p>1080P 50帧/秒 位宽(每个像素点位数)8bit。</p>
<p><code>每秒视频size = 1920*1280*8*50/1024/1024 = 937.5 Mb</code></p>
<h1 id="采集源"><a href="#采集源" class="headerlink" title="采集源"></a>采集源</h1><h2 id="摄像头采集"><a href="#摄像头采集" class="headerlink" title="摄像头采集"></a>摄像头采集</h2><p>对于视频内容的采集，目前摄像头采集是社交直播中最常见的采集方式，比如主播使用手机的前置和后置摄像头拍摄。在现场直播场景中，也有专业的摄影、摄像设备用来采集。安防监控场景中也有专业的摄像头进行监控采集。</p>
<h2 id="屏幕录制"><a href="#屏幕录制" class="headerlink" title="屏幕录制"></a>屏幕录制</h2><p>手机屏幕录制采集的方式在手机游戏直播场景中非常常见，Android实现屏幕录制的功能比较简单。而 iOS 则由于系统本身没有开放屏幕录制的权限而没法直接操作，但对于 iOS 9 以上的版本，是有个取巧的办法，可以通过模拟一个 AirPlay 镜像连接到（当前 App）自身，这样就可以在软件上捕获到屏幕上的任何操作，达到录制屏幕的效果。</p>
<p>在教育直播或者会场演讲场合，经常需要录制电脑桌面上 PPT，针对这种场景，目前市面上比较方便的方案是使用开源的桌面推流工具 <a href="https://obsproject.com/" target="_blank" rel="noopener">OBS：Open Broadcaster Software</a> 来进行屏幕录制和推流</p>
<h2 id="从视频文件推流"><a href="#从视频文件推流" class="headerlink" title="从视频文件推流"></a>从视频文件推流</h2><p>除了从硬件设备采集视频进行推流之外，我们也可能需要将一个视频或者音频文件以直播流的形式实时传输给观众，比如在线电台或者电视节目，它们的输入可能直接来自于一些已经录制剪辑好的视频内容。</p>
<h1 id="开放式设计"><a href="#开放式设计" class="headerlink" title="开放式设计"></a>开放式设计</h1><p>为了支持市场上所有采集源的接入，SDK 应该采用开放式的设计，只要采集源实现方遵循相应的接口，即可支持任意的采集源。</p>
<img src="/2019/08/01/直播/直播技术/直播技术二-采集/source.jpeg">
<p>图中我们把采集的内容分为图像和音频，其中图像的采集源包含摄像头、屏幕录制或者本地的视频文件，甚至是其它需要重新定义和实现的采集源。而音频的采集源包含麦克风、系统声音或者本地音频文件，当然也可以为它定义别的输入源。</p>
<p>这样设计最大的好处在于，可以以轻量的设计方式支持丰富的采集源，而采集源的具体实现也可以交给使用者。</p>
<h1 id="参考-amp-扩展"><a href="#参考-amp-扩展" class="headerlink" title="参考&amp;扩展"></a>参考&amp;扩展</h1><ul>
<li><a href="https://blog.qiniu.com/archives/6713" target="_blank" rel="noopener">《视频直播技术详解》系列之二：采集</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/01/直播/直播技术/直播技术一-开篇/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="风">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="风">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/01/直播/直播技术/直播技术一-开篇/" itemprop="url">直播技术一-开篇</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-01T16:02:14+08:00">
                2019-08-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/直播/" itemprop="url" rel="index">
                    <span itemprop="name">直播</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="直播技术大纲"><a href="#直播技术大纲" class="headerlink" title="直播技术大纲"></a>直播技术大纲</h1><p>（一）采集</p>
<p>（二）处理</p>
<p>（三）编码和封装</p>
<p>（四）推流和传输</p>
<p>（五）延迟优化</p>
<p>（六）现代播放器原理</p>
<p>（七）SDK 性能测试模型</p>
<h1 id="直播流程"><a href="#直播流程" class="headerlink" title="直播流程"></a>直播流程</h1><img src="/2019/08/01/直播/直播技术/直播技术一-开篇/stream.png">
<h2 id="采集"><a href="#采集" class="headerlink" title="采集"></a>采集</h2><p>iOS 系统因为软硬件种类不多，硬件适配性较好，所以比较简单。Android 则不同，市面上硬件机型非常多，难以做到一个库适配所有硬件。PC 端的采集也跟各种摄像头驱动有关，推荐使用目前市面上最好用的 PC 端开源免费软件 OBS。</p>
<h2 id="处理"><a href="#处理" class="headerlink" title="处理"></a>处理</h2><p>视频音频处理，美颜、水印、混音等</p>
<h2 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h2><p>编码主要难点有两个：</p>
<ol>
<li>处理硬件兼容性问题。</li>
<li>在高 fps、低 bitrate 和音质画质之间找到平衡。</li>
</ol>
<p>iOS 端硬件兼容性较好，可以直接采用硬编。而 Android 的硬编的支持则难得多，需要支持各种硬件机型，推荐使用软编。</p>
<h2 id="推流和传输"><a href="#推流和传输" class="headerlink" title="推流和传输"></a>推流和传输</h2><p>传输涉及到很多端：主播端 – 服务端 – CDN – 观众端。</p>
<p>传统的 CDN 在新时代显得心有余力不足。实现稳定高速的推流上传需要自己做一个直播专属的实时流网络</p>
<h2 id="转码"><a href="#转码" class="headerlink" title="转码"></a>转码</h2><p>为了让主播推上来的流<strong>适配各个平台端各种不同协议</strong>，需要在服务端做一些流处理工作，比如转码成不同格式支持不同协议如 RTMP、HLS 和 FLV，一路转多路流来适配各种不同的网络状况和不同分辨率的终端设备。</p>
<p>同时，为了配合一些运营需求，比如一些监管部门的要求，需要内容识别如鉴黄的功能。</p>
<h2 id="解码和渲染"><a href="#解码和渲染" class="headerlink" title="解码和渲染"></a>解码和渲染</h2><p>解码和渲染，也即音视频的播放，目前 iOS 端的播放兼容性较好，在延迟可接受的情况下使用 HLS 协议是最好的选择。Android 的硬件解码和编码一样也存在兼容性问题，目前比较好的开源播放器是基于 ffplay 的 <strong>ijkplayer</strong></p>
<p>重点：播放器的原理，以及现代视频播放器的基本架构</p>
<h1 id="直播场景化解决方案"><a href="#直播场景化解决方案" class="headerlink" title="直播场景化解决方案"></a>直播场景化解决方案</h1><p>直播场景如社交直播和游戏直播</p>
<p>背后的技术方案不仅涉及到直播基础服务，还可能涉及到和场景相关的其它技术，如聊天、点赞和弹幕的支持</p>
<h1 id="直播云整体架构设计图"><a href="#直播云整体架构设计图" class="headerlink" title="直播云整体架构设计图"></a>直播云整体架构设计图</h1><img src="/2019/08/01/直播/直播技术/直播技术一-开篇/七牛直播云整体架构设计图.png">
<h1 id="参考-amp-扩展"><a href="#参考-amp-扩展" class="headerlink" title="参考&amp;扩展"></a>参考&amp;扩展</h1><ul>
<li><a href="https://blog.qiniu.com/archives/6606" target="_blank" rel="noopener">《视频直播技术详解》系列之一：开篇</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/31/直播/视频/视频相关基础概念/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="风">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="风">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/31/直播/视频/视频相关基础概念/" itemprop="url">视频相关基础概念</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-31T14:52:14+08:00">
                2019-07-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/视频/" itemprop="url" rel="index">
                    <span itemprop="name">视频</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="分辨率"><a href="#分辨率" class="headerlink" title="分辨率"></a>分辨率</h1><p>分辨率是以横向和纵向的像素数量来衡量的，表示平面图像的精细程度。</p>
<p>视频精细程度并不只取决于视频分辨率，还取决于屏幕分辨率。</p>
<p>1080P 的 <strong>P</strong> 指 <strong>Progressive scan</strong>（逐行扫描），即垂直方向像素点，也就是 “高”，所以 1920X1080 叫 1080P， 不叫 1920P。</p>
<p>当 720P 的视频在 1080P 屏幕上播放时，需要将图像放大，<strong>放大操作也叫上采样</strong>。</p>
<p>上采样几乎都是采用内插值方法，即在原有图像的像素点之间采用合适的插值算法插入新的元素，所以图像放大也称为图像插值。</p>
<p>当 1080P 的视频在 720P 屏幕上播放时，需要将图像缩小，<strong>缩小操作也叫下采样</strong>。</p>
<p>下采样的定义为：对于一个样值序列，间隔几个样值取样一次，得到新序列。</p>
<h1 id="GOP"><a href="#GOP" class="headerlink" title="GOP"></a>GOP</h1><p>Group of Pictures</p>
<p>图像组或画面组，一个GOP就是一组连续的画面</p>
<p>GOP策略影响<strong>编码质量</strong></p>
<p><strong>GOP 越长，理论上画面越高清</strong>。但是生成 HLS 直播时，最小切割粒度也是一个 GOP，所以针对交互直播，通常不建议 GOP 设置太长。直播一般 2 个关键帧间隔即可（也就是 2s）。</p>
<p>在H264中图像以GOP图像组为单位进行组织，一个GOP图像组是一段图像编码后的数据流，以I帧开始</p>
<h2 id="I、P、B-帧"><a href="#I、P、B-帧" class="headerlink" title="I、P、B 帧"></a>I、P、B 帧</h2><p>MPEG编码将画面（即帧）分为I、P、B三种。</p>
<p>帧内压缩生成I帧，帧间压缩生成B帧和P帧</p>
<ul>
<li><strong>I</strong> <strong>关键帧</strong> 是内部编码帧。压缩率是7（跟JPG差不多）</li>
<li><strong>P</strong>  <strong>参考帧</strong> 是前向预测帧。压缩率是20<ul>
<li>参考之前的I帧编码的，只包含差异部分编码（体积很小）</li>
<li>P 帧没有完整画面数据，只有与前一帧的画面差别的数据</li>
<li>解码时需要用之前缓存的画面叠加上本帧定义的差别，生成最终画面。</li>
<li>P 帧是参考帧(后面P帧/前后的B帧的参考帧),它可能造成解码错误的扩散;</li>
</ul>
</li>
<li><strong>B</strong> 是双向预测内插帧。压缩率是50（比较耗CPU）<ul>
<li>参考前后的帧编码的，只包含差异部分编码（体积很小）</li>
<li>B 帧记录的是本帧与前后帧的差别</li>
<li>解码时需要用前后画面叠加本帧定义的差别，生成最终的画面。</li>
<li>B 帧不是参考帧,不会造成解码错误的扩散。</li>
</ul>
</li>
</ul>
<p>简单地讲，I帧是一个完整的画面，而P帧和B帧记录的是相对于I帧的变化。</p>
<p>没有I帧，P帧和B帧就无法解码，这就是MPEG格式难以精确剪辑的原因，也是我们之所以要微调头和尾的原因。</p>
<h3 id="花屏和跳跃"><a href="#花屏和跳跃" class="headerlink" title="花屏和跳跃"></a>花屏和跳跃</h3><p>丢失掉了“关键帧”，随后的几帧图像无法正常地解码，因此产生“花屏”现象。</p>
<p>从技术的角度，怎么解决“花屏”现象呢？</p>
<p>当我们在视频传输过程中，通过帧序号发现丢帧后，可以跳过随后的非“关键帧”，直到遇到下一个关键帧再送入解码。这样的确可以解决“花屏”现象，但是由于跳跃了很多帧，因此会出现视频图像的不连续情况（即“跳跃”现象）。</p>
<h2 id="IDR"><a href="#IDR" class="headerlink" title="IDR"></a>IDR</h2><p>IDR（Instantaneous Decoding Refresh）–即时解码刷新。</p>
<p>一个序列的第一个图像叫做 IDR 图像（立即刷新图像），IDR 图像都是 I 帧图像。H.264 引入 IDR 图像是为了<strong>解码的重同步</strong>，当解码器解码到 IDR 图像时，立即将参考帧队列清空，将已解码的数据全部输出或抛弃，重新查找参数集，开始一个新的序列。这样，如果前一个序列出现重大错误，在这里可以获得重新同步的机会。IDR图像之后的图像永远不会使用IDR之前的图像的数据来解码。</p>
<h2 id="MPEG-2-帧结构"><a href="#MPEG-2-帧结构" class="headerlink" title="MPEG-2 帧结构"></a>MPEG-2 帧结构</h2><p>MPEG-2压缩的帧结构有两个参数，</p>
<ul>
<li>GOP<ul>
<li>一般可按编码方式从1－15；</li>
<li>两个I帧之间的间隔</li>
</ul>
</li>
<li>I帧和P帧之间B帧的数量<ul>
<li>一般是1－2个。</li>
<li>多少帧里出现一次P帧</li>
</ul>
</li>
</ul>
<h1 id="比特率"><a href="#比特率" class="headerlink" title="比特率"></a>比特率</h1><p>比特率即码率，在多媒体领域，指单位时间播放音频或视频的比特数，可以理解成吞吐量或带宽。</p>
<p>单位为 bps , 即 bits per second，每秒传输的数据量</p>
<p>在一个视频中，不同时段画面的复杂程度是不同的，比如高速变化的场景和几乎静止的场景，所需的数据量也是不同的，若都使用同一种比特率是不太合理的，所以引入了动态比特率。</p>
<h2 id="动态比特率"><a href="#动态比特率" class="headerlink" title="动态比特率"></a>动态比特率</h2><p>简称为 <strong>VBR</strong>，即 Variable Bit Rate，比特率可以随着图像复杂程度的不同而随之变化。</p>
<p>图像内容简单的片段采用较小的码率，图像内容复杂的片段采用较大的码率，这样既保证了播放质量，又兼顾了数据量的限制。</p>
<p>比如 RMVB 视频文件，其中的 VB 就是指 VBR，表示采用动态比特率编码方式，达到播放质量与体积兼得的效果。</p>
<h2 id="静态比特率"><a href="#静态比特率" class="headerlink" title="静态比特率"></a>静态比特率</h2><p>简称为 <strong>CBR</strong>，即 Constant Bit Rate，比特率恒定。</p>
<p>图像内容复杂的片段质量不稳定，图像内容简单的片段质量较好。</p>
<p>除 VBR 和 CBR 外，还有 <strong>CVBR</strong>（Constrained VariableBit Rate） 、<strong>ABR</strong> (Average Bit Rate) 等等。</p>
<h1 id="采样率"><a href="#采样率" class="headerlink" title="采样率"></a>采样率</h1><p>定义：每秒从连续信号中提取并组成离散信号的采样个数，单位为赫兹（Hz）。</p>
<h2 id="音频中的采样率"><a href="#音频中的采样率" class="headerlink" title="音频中的采样率"></a>音频中的采样率</h2><p>指把音频信号数字化后 1 个通道 1 秒钟采取多少个样本，如 44.1kHz 的采样率，就是指 1 个通道 1 秒钟有 44.1k 个数据。</p>
<h2 id="视频中的采样率"><a href="#视频中的采样率" class="headerlink" title="视频中的采样率"></a>视频中的采样率</h2><p>视频一般<strong>不标识</strong>采样率属性</p>
<p>采样率本身就是一个可泛化的概念，对于视频来说，若非要用采样率来描述的话，那就要分为两个层面：<strong>帧频和场频</strong>。</p>
<p>从帧频层面来说，采样率就是指<strong>帧率</strong>，指 1 秒钟显示多少帧图像。</p>
<p>从场频层面来说，采样率就是指<strong>像素频率</strong>，指 1 秒钟显示多少个像素。</p>
<p>像素频率是显示器的一个指标，可以理解成显示器的最大带宽，可以起到限制<strong>分辨率和刷新率(每秒刷新的次数，Hz)</strong>的作用</p>
<p>根据含义可得出一个公式：</p>
<p><code>像素频率 = 刷新率 X 帧像素数量</code></p>
<p><code>像素频率 = 60Hz*1920*1080/1024/1024 = 118.65 MHz</code></p>
<h1 id="帧率"><a href="#帧率" class="headerlink" title="帧率"></a>帧率</h1><p>定义：用于测量显示帧数的量度。单位为 FPS（Frames per Second，每秒显示帧数）或赫兹（Hz）。</p>
<p>帧率越高，画面越流畅、逼真，对显卡的处理能力要求越高，数据量越大。</p>
<p>根据人眼视觉暂留原理，每秒超过 <strong>24</strong> 帧的图像变化看上去是平滑连续的，这样的连续画面叫视频。</p>
<h2 id="帧率主观感受"><a href="#帧率主观感受" class="headerlink" title="帧率主观感受"></a>帧率主观感受</h2><img src="/2019/07/31/直播/视频/视频相关基础概念/帧率主观感受.jpeg">
<p>视频长度是8秒。分辨率是QCIF (176 x 144) 。原始帧率是25 fps。</p>
<p>实验过程中，帧率变换为以下几种：25， 12.5， 8.33， 6.25， 5 以及 2.5 fps。</p>
<p>主观感受（MOS）取的是各个测试序列的平均值，包含了95%的置信区间。</p>
<p>可见帧率超过15帧以后，人眼就会获得很好的感受。而如果低于12.5帧的话，人眼的主观感受会随着帧率的下降而迅速下降。</p>
<h2 id="24-帧"><a href="#24-帧" class="headerlink" title="24 帧"></a>24 帧</h2><p>对电影等视频而言，24 帧 是流畅的；对游戏来说 是不流畅的</p>
<h3 id="两者图像生成原理不同"><a href="#两者图像生成原理不同" class="headerlink" title="两者图像生成原理不同"></a>两者图像生成原理不同</h3><p>电影的每一帧都包含一段时间的信息，会有动态模糊；而游戏的画面则是由显卡计算生成的，一帧只包含那一瞬间的信息</p>
<h3 id="电影的FPS是稳定的，而游戏则是不稳定的"><a href="#电影的FPS是稳定的，而游戏则是不稳定的" class="headerlink" title="电影的FPS是稳定的，而游戏则是不稳定的"></a>电影的FPS是稳定的，而游戏则是不稳定的</h3><p>电影若为 24fps，那就表示每隔 1/24 秒刷新一次画面，帧间隔是固定的。</p>
<p>游戏若为 60fps，表示大约每隔 1/60 秒刷新一次画面，帧间隔是不稳定的，即使 1 秒能显示 60 帧，那也可能是前半秒显示了 59 帧，后半秒显示了 1 帧。</p>
<p>所以游戏卡顿有两个解决方案：提高帧率，或增加动态模糊效果(游戏设置都有)。</p>
<h1 id="参考-amp-扩展"><a href="#参考-amp-扩展" class="headerlink" title="参考&amp;扩展"></a>参考&amp;扩展</h1><ul>
<li><a href="https://www.jianshu.com/p/1379ed99783e" target="_blank" rel="noopener">视频相关的理论知识与基础概念</a></li>
<li><a href="https://blog.csdn.net/lcalqf/article/details/53048347" target="_blank" rel="noopener">h264 Gop组 I 、P、B 帧</a></li>
<li><a href="https://blog.csdn.net/qq_29350001/article/details/73770702" target="_blank" rel="noopener">图像和流媒体 – I 帧,B帧,P帧,IDR帧的区别</a></li>
<li><a href="https://blog.csdn.net/leixiaohua1020/article/details/84490329" target="_blank" rel="noopener">视频帧率对人眼主观感受的影响 2</a> 雷霄骅</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/07/30/web/web渲染/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="风">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="风">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/30/web/web渲染/" itemprop="url">web渲染</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-07-30T15:28:14+08:00">
                2019-07-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/web/" itemprop="url" rel="index">
                    <span itemprop="name">web</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="基础术语"><a href="#基础术语" class="headerlink" title="基础术语"></a>基础术语</h1><h2 id="Rendering"><a href="#Rendering" class="headerlink" title="Rendering"></a>Rendering</h2><ul>
<li><strong>SSR 服务端渲染</strong>: Server-Side Rendering - 服务端渲染HTML.</li>
<li><strong>CSR 客户端渲染</strong>: Client-Side Rendering - 客服端浏览器使用DOM渲染.<br><strong>Rehydration 同构</strong>: 服务端和客户端使用同一份DOM渲染<br><strong>Prerendering 预渲染</strong>: 编译时启动一个客户端渲染出初始化的静态HTML</li>
</ul>
<h2 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h2><ul>
<li><strong>TTFB</strong>: Time to First Byte - seen as the time between clicking a link and the first bit of content coming in.</li>
<li><strong>FP</strong>: First Paint - the first time any pixel gets becomes visible to the user.</li>
<li><strong>FCP</strong>: First Contentful Paint - the time when requested content (article body, etc) becomes visible.</li>
<li><strong>TTI</strong>: Time To Interactive - the time at which a page becomes interactive (events wired up, etc).</li>
</ul>
<h2 id="SPA-和-MPA"><a href="#SPA-和-MPA" class="headerlink" title="SPA 和 MPA"></a>SPA 和 MPA</h2><p><strong>SPA 单页面应用</strong> Single-page Application </p>
<img src="/2019/07/30/web/web渲染/spa.png">
<p><strong>MPA 多页面应用多页面应用</strong> Multi-page Application </p>
<img src="/2019/07/30/web/web渲染/mpa.png">
<h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3><table>
<thead>
<tr>
<th></th>
<th>单页面应用</th>
<th>多页面应用</th>
</tr>
</thead>
<tbody>
<tr>
<td>组成</td>
<td>一个外壳页面和多个页面片段组成</td>
<td>多个完整页面构成</td>
</tr>
<tr>
<td>资源共用(css,js)</td>
<td>共用，只需在外壳部分加载</td>
<td>不共用，每个页面都需要加载</td>
</tr>
<tr>
<td>刷新方式</td>
<td>页面局部刷新或更改</td>
<td>整页刷新</td>
</tr>
<tr>
<td>url 模式</td>
<td>a.com/#/pageone  a.com/#/pagetwo</td>
<td>a.com/pageone.html  a.com/pagetwo.html</td>
</tr>
<tr>
<td>用户体验</td>
<td>用户体验良好。首屏时间慢，页面切换快</td>
<td>用户体验比较差。首屏时间快，页面切换慢</td>
</tr>
<tr>
<td>转场动画</td>
<td>容易实现</td>
<td>无法实现</td>
</tr>
<tr>
<td>数据传递</td>
<td>容易</td>
<td>依赖 url传参、或者cookie 、localStorage等</td>
</tr>
<tr>
<td>搜索引擎优化(SEO)</td>
<td>SEO差。需要单独方案、实现较为困难、可利用服务器端渲染(SSR)优化</td>
<td>SEO效果好。实现方法简易</td>
</tr>
<tr>
<td>使用范围</td>
<td>高要求的体验度、追求界面流畅的应用</td>
<td>适用于追求高度支持搜索引擎的应用</td>
</tr>
<tr>
<td>开发成本</td>
<td>较高，常需借助专业的框架</td>
<td>较低 ，但页面重复代码多</td>
</tr>
<tr>
<td>维护成本</td>
<td>相对容易</td>
<td>相对复杂</td>
</tr>
</tbody>
</table>
<h1 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h1><p>后端渲染 – 前端渲染 – 后端渲染</p>
<p>看一门技术的发展主要应该看背后的人是谁，应用场景是哪些，最后才是技术细节。</p>
<ol>
<li><p>后端发现页面中的 JS 很麻烦（虽然简单，但是坑多），于是让公司招聘专门写 JS 的人，也就是前端</p>
</li>
<li><p>前端名义上是程序员，实际上就是在写样式（CSS）和做特效(JS)，所以所有程序员中前端工资最低，职位也最低。所以前后端的鄙视链就出现了。</p>
</li>
<li>nodejs 和前端 mvc 的兴起让前端变得复杂起来，前端发现翻身的机会，于是全力支持这两种技术，造成本不该做成 SPA 的网站也成了 spa。慢慢地前后端分离运动从大公司开始兴起，目的就是前端脱离后端的指指点点，独立发展。（表面上是为了「代码分离」，实际上是为了「人员分离」，也就是「前后端分家」，前端不再附属于后端团队）</li>
<li>spa 之后发现 <strong>seo</strong> 问题很大，而且<strong>首屏渲染速度</strong>很慢，但是自己选的路再难走也要走下去，于是用 nodejs 在服务端渲染这一条路被看成是一条出路</li>
<li>其实这是第二个翻身的机会，如果 nodejs 服务器渲染成为主流，其实就相当于前端把后端的大部分工作给抢了，工资压过普通后端指日可待</li>
<li>然而结果是 nodejs 服务端渲染始终是小众，因为后端也没那么脆弱，java php rails 十多年沉淀的技术岂是你说推翻就推翻的，已经运行多年的项目又岂是容你随便用 nodejs 重写的，另一方面 golang 等技术的兴起也给 nodejs 不少压力。最终只有少部分前端特别强势的团队成功用上了 Node.js 做渲染（比如阿里的一些团队），大部分公司依然是用 PHP 渲染 HTML。</li>
<li>于是 nodejs 退一步说好好好我不抢你们的工作，我只做中间层（大部分工作就是渲染页面和调用后台接口），绝不越雷池。后端说算你识相。现在 nodejs 主要搞什么微服务，也是为了抢后端还没注意的市场。</li>
</ol>
<h2 id="前端的矛盾"><a href="#前端的矛盾" class="headerlink" title="前端的矛盾"></a>前端的矛盾</h2><p>前后端代码可以分离，但是人员绝对不应该分离。前后端撕逼的事情在大公司天天都在发生，全都是因为前后是两个团队，利益不同。实际上前端推 nodejs 渲染就是在试图重新让前后端合成一体。</p>
<p>但是前端不能明说这件事，因为如果要把前后端部门合并，拆掉的肯定是前端部门。</p>
<p>合，则相当于自断前程。<br>不合，则永远没法解决seo和首屏加载慢的问题。<br>所以前端真的挺矛盾的。</p>
<h2 id="JS的矛盾"><a href="#JS的矛盾" class="headerlink" title="JS的矛盾"></a>JS的矛盾</h2><p>凡是浏览器上的框架（Vue React）都说自己能适应「复杂」场景，凡是 Node.js 上的框架（express fastify koa）都说自己是「轻量级」框架。</p>
<p>为啥？因为浏览器是 JS 的主战场，而且无敌手。而服务器上，JS 的经验积累还是太少了，搞企业级服务，Node.js 是敌不过 Java、PHP 的，没办法，发展得太晚了。所以目前只能搞「轻量级」咯。<code>egg.js</code> 号称是企业级 Node.js 框架，用过的人来评我就不评了。</p>
<h2 id="大前端"><a href="#大前端" class="headerlink" title="大前端"></a>大前端</h2><p>有些大佬提出「大前端」的概念，意思是前端也要会后端，但是我们心还是前端的。</p>
<p>这不就是把以前的『前后端一个人做』换了个说法嘛。以前是后端一个人做，现在前端一个做。</p>
<p>反正你现在让后端去学前端，后端肯定是不愿意躺这浑水的。只能前端自己想办法咯。</p>
<p>想来想去就只有 Node.js 中间层做 HTML 渲染了。</p>
<p>由于阿里 nodejs 用得还算多，却招不到人，所以从功利的角度出发，也许你学 nodejs 比学 java 更容易进阿里，毕竟阿里的 java 大神多如云，nodejs 大神却不多。</p>
<h2 id="开历史倒车？"><a href="#开历史倒车？" class="headerlink" title="开历史倒车？"></a>开历史倒车？</h2><p>其实并<strong>不是</strong>。以前是 Back-end（或者说 Full-stack）工程师负责 SSR，但是现在是 Front-end 工程师负责 SSR 了啊。在目前这个知识爆炸的年代，前后端的职能目前已经被分割得很开，大家都不愿意去淌对方那摊混水，而 Rendering 这事从语义上出发就属于 Front-end 的范畴，让 Back-end 去做这事，其实很多人是不愿意的。</p>
<p>回到问题本身，SSR 的「又流行」其实是 Front-end 社区<strong>工具栈不断进化</strong>的体现，也是历史的必然啊。几年前，SPA/CSR 概念的大热，让很多 Front-end 把他们当做万金油了。其实大家都知道 CSR 有着 SEO 和 页面渲染速度的问题，但苦于社区中没有解决这个问题的工具栈，所以大家都对这个问题<strong>视而不见</strong>了。</p>
<p>而随着 Front-end 社区造轮子大潮的兴起，出现了一个很关键的历史转折点 —— Node.js 的出现。Node.js 赋予了 Front-end 在服务端执行 Js 的能力，有了这个环境和土壤，Front-end 工程师们终于可以考虑如何用 Js 来实现 SSR 了，于是 React 和 Vue 等主流框架后面开始支持 SSR 也就成了必然。</p>
<p>所以之前并不是不流行，而是因为前后端职能的分离，Back-end 不愿意做这事了，Front-end 没有条件去做。现在有条件了，自然又开始流行了。</p>
<h1 id="利弊"><a href="#利弊" class="headerlink" title="利弊"></a>利弊</h1><img src="/2019/07/30/web/web渲染/vs.png">
<h1 id="同构"><a href="#同构" class="headerlink" title="同构"></a>同构</h1><p>为了解决客户端渲染首屏慢与 SEO 问题，同构开始出现。</p>
<p>同构：前后端共用 JS，首次渲染时使用 Node.js 来直出 HTML。一般来说同构渲染是介于前后端中的共有部分。</p>
<p>简单说下在使用 Vue SSR（nuxt）的一些坑：</p>
<p>服务端必须是 node.js 或者专门跑个 node.js 来支持；</p>
<p>document 对象找不到，由于前端使用的 window，在 node 环境不存在；</p>
<p>数据预获取时，组件尚未实例化（无法使用 this ），于是在 created 生命钩子调用 method 里的方法行不通，数据请求及格式化等操作都应该放置在专门的数据预取存储容器（data store）或”状态容器（state container）”中处理；</p>
<p>string-based 模板性能肯定要比 virtual-dom-based 模板的性能好。string-base 模板只要填数据即可，virtual-dom-based 模板需要经历 Vue 模板语法 —&gt; Vnode —&gt; 拼接字符串 html 的过程。 有关性能的消耗对比，可以参考这篇文章<a href="https://mp.weixin.qq.com/s?__biz=MzUxMzcxMzE5Ng==&amp;mid=2247485601&amp;idx=1&amp;sn=97a45254a771d13789faed81316b465a&amp;source=41#wechat_redirect" target="_blank" rel="noopener">实测Vue SSR的渲染性能：避开20倍耗时</a>；</p>
<p>缓存方面，只能做到页面级的缓存。如果用户特定（user-specific），即对于不同用户需要渲染不同内容，缓存是不可用的。</p>
<p>是否有其他解决客户端渲染不足之处的方法？</p>
<p>答案肯定是有的：</p>
<p>处理 SEO 问题时，使用 prerender… 、升级搜索引擎，以及其他。</p>
<p>白屏可以加 loading、Skeleton Screen 效果、以及其他。</p>
<h1 id="参考-amp-扩展"><a href="#参考-amp-扩展" class="headerlink" title="参考&amp;扩展"></a>参考&amp;扩展</h1><ul>
<li><a href="https://developers.google.com/web/updates/2019/02/rendering-on-the-web" target="_blank" rel="noopener">Google开发者：SSR、CSR、预渲染、伪同构等渲染架构</a></li>
<li><a href="https://blog.csdn.net/B9Q8e64lO6mm/article/details/79418969" target="_blank" rel="noopener">知乎问答：为什么现在又流行服务器端渲染html？</a></li>
<li><a href="https://juejin.im/entry/5a111eb7f265da431c6fe51c" target="_blank" rel="noopener">服务端渲染 vs 客户端渲染</a></li>
<li><a href="https://juejin.im/post/5a0ea4ec6fb9a0450407725c" target="_blank" rel="noopener">前端：你要懂的单页面应用和多页面应用</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/10/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><span class="page-number current">11</span><a class="page-number" href="/page/12/">12</a><span class="space">&hellip;</span><a class="page-number" href="/page/31/">31</a><a class="extend next" rel="next" href="/page/12/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="风" />
            
              <p class="site-author-name" itemprop="name">风</p>
              <p class="site-description motion-element" itemprop="description">随心而动，随刃而行</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">310</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">19</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">71</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">风</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  







  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/canvas_lines.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
